{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "import paho.mqtt.publish as publish\n",
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import re\n",
    "import os\n",
    "import threading\n",
    "from PIL import Image \n",
    "# import Image\n",
    "\n",
    "\n",
    "# ------------------------- yolov5s 모델 import -------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "from models.yolo import Model, attempt_load\n",
    "from utils.general import check_requirements, set_logging\n",
    "from utils.google_utils import attempt_download\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "check_requirements(Path(__file__).parent / 'requirements.txt', exclude=('tensorboard', 'pycocotools', 'thop'))\n",
    "# set_logging(verbose=verbose)\n",
    "device = None\n",
    "\n",
    "name1 = 'yolov5_custom_pink.pt'\n",
    "fname1 = Path(name1).with_suffix('.pt')  # checkpoint filename\n",
    "model1 = attempt_load(fname1, map_location=torch.device('cpu'))\n",
    "model1 = model1.autoshape()  # for file/URI/PIL/cv2/np inputs and NMS\n",
    "model1.conf = 0.5\n",
    "\n",
    "name2 = 'yolov5_custom.pt'\n",
    "fname2 = Path(name2).with_suffix('.pt')  # checkpoint filename\n",
    "model2 = attempt_load(fname2, map_location=torch.device('cpu'))\n",
    "model2 = model2.autoshape()  # for file/URI/PIL/cv2/np inputs and NMS\n",
    "model2.conf = 0.5\n",
    "\n",
    "device = select_device('0' if torch.cuda.is_available() else 'cpu') if device is None else torch.device(device)\n",
    "# ------------------------- 모델 import fin -------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "on_connect는 subscriber가 브로커에 연결하면서 호출할 함수\n",
    "rc가 0이면 정상접속이 됐다는 의미\n",
    "\"\"\"\n",
    "\n",
    "# ------------------------- 구조물 인식 함수 -------------------------\n",
    "def notice(img):\n",
    "    # 현재 이미지 불러오기\n",
    "    results_img = model1(img)\n",
    "    results_img_xy_df = results_img.pandas().xyxy[0]\n",
    "    results_img_xy_df = results_img_xy_df.sort_values(by=['confidence'], ascending=False)\n",
    "    results_img_xy_df = results_img_xy_df.iloc[0:1]\n",
    "\n",
    "    if len(results_img_xy_df) != 0 :\n",
    "        print('******************if**********************')\n",
    "        x_center = (results_img_xy_df[results_img_xy_df['name'] == 'pink_point'].iloc[:, 2] + results_img_xy_df[results_img_xy_df['name'] == 'pink_point'].iloc[:, 0]) / 2\n",
    " \n",
    "    else:\n",
    "        print('******************else********************')\n",
    "        return 'X'\n",
    "\n",
    "    # 카메라 중점\n",
    "    print('\\n')\n",
    "    print(x_center)\n",
    "    cam_view_center = 360\n",
    "    if cam_view_center*0.6 < float(x_center) < cam_view_center*1.4:\n",
    "        print(\"C\")\n",
    "        return 'C'\n",
    "    elif cam_view_center < float(x_center):\n",
    "        print(\"R\")\n",
    "        return 'R'\n",
    "    elif cam_view_center > float(x_center):\n",
    "        print(\"L\")\n",
    "        return 'L'\n",
    "\n",
    "\n",
    "# ------------------------- yolov5s 모델로 input 이미지 디텍팅 함수 -------------------------\n",
    "def objectDetection(img):\n",
    "    results_img = model2(img)\n",
    "    results_img.crop()\n",
    "#     results_img.save()\n",
    "\n",
    "# ------------------------- EasyOCR reader 생성 -------------------------\n",
    "reader = easyocr.Reader(['ar'])\n",
    "\n",
    "\n",
    "# ------------------------- OCR_v1 -------------------------\n",
    "# OCR 버전마다 전처리 과정이 다름\n",
    "def OCR_pn(img):\n",
    "    img = cv2.imread(img) # 이미지 로드\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # 배경에 그레이 적용\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC) # 사이즈 정규화(키우기)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0) # 이미지에 블러 처리\n",
    "\n",
    "    # ------------------- 기울기 조정 start -------------------\n",
    "    canny = cv2.Canny(blur, 700, 350, apertureSize = 5, L2gradient = True) # 이미지 외곽선만 추출\n",
    "    lines = cv2.HoughLinesP(canny, 1, np.pi / 180, 50, minLineLength = 3, maxLineGap = 150) # 직선 찾기\n",
    "\n",
    "    angle = 0\n",
    "    maxdim = 0\n",
    "    # 각도 조정\n",
    "    if not (lines is None):\n",
    "        for i in lines:\n",
    "            xdim = i[0][2] - i[0][0]\n",
    "            ydim = i[0][3] - i[0][1]\n",
    "            iangle = math.atan2(ydim, xdim)*180/np.pi\n",
    "            dim = math.sqrt((xdim * xdim) + (ydim * ydim))\n",
    "            if abs(angle) < 40 and maxdim < dim:\n",
    "                maxdim = dim\n",
    "                angle =iangle\n",
    "\n",
    "    roih, roiw, roic = img.shape\n",
    "    matrix = cv2.getRotationMatrix2D((roiw/2, roih/2), angle, 1)\n",
    "    roi = cv2.warpAffine(img, matrix, (roiw, roih))\n",
    "    # ------------------- 기울기 조정 fin -------------------\n",
    "\n",
    "    roi = cv2.resize(roi, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur_2 = cv2.GaussianBlur(roi, (5,5), 0)\n",
    "    \n",
    "    plate_num = \"\"\n",
    "    try:\n",
    "        # tesseract OCR 적용\n",
    "        text = pytesseract.image_to_string(blur_2, config='-c tessedit_char_whitelist=0123456789 --psm 7 --oem 1') # whitelist: 숫자만 인식\n",
    "        plate_num = re.sub('[\\W_]+', '', text) # 특수문자 제거\n",
    "    except:\n",
    "        text = None\n",
    "    \n",
    "    plate_num = re.sub('[\\W_]+', '', text)   \n",
    "    return plate_num[-4:]\n",
    "\n",
    "\n",
    "# ------------------------- OCR_v2 -------------------------\n",
    "def OCR_pn2(img):\n",
    "    img = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    \n",
    "    plate_num = \"\"\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(blur, config='-c tessedit_char_whitelist=0123456789 --psm 7 --oem 1')\n",
    "        plate_num = re.sub('[\\W_]+', '', text)            \n",
    "    except:\n",
    "        text = None\n",
    "\n",
    "    plate_num = re.sub('[\\W_]+', '', text)   \n",
    "    return plate_num[-4:]\n",
    "\n",
    "\n",
    "# ------------------------- OCR_v3 -------------------------\n",
    "def OCR_pn3(img):\n",
    "    img = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # ------------------- 기울기 조정 start -------------------\n",
    "    canny = cv2.Canny(blur, 700, 350, apertureSize = 5, L2gradient = True)\n",
    "    lines = cv2.HoughLinesP(canny, 1, np.pi / 180, 50, minLineLength = 3, maxLineGap = 150)\n",
    "\n",
    "    angle = 0\n",
    "    maxdim = 0\n",
    "    if not (lines is None):\n",
    "        for i in lines:\n",
    "            xdim = i[0][2] - i[0][0]\n",
    "            ydim = i[0][3] - i[0][1]\n",
    "            iangle = math.atan2(ydim, xdim)*180/np.pi\n",
    "            dim = math.sqrt((xdim * xdim) + (ydim * ydim))\n",
    "            if abs(angle) < 40 and maxdim < dim:\n",
    "                maxdim = dim\n",
    "                angle =iangle\n",
    "\n",
    "    roih, roiw, roic = img.shape\n",
    "    matrix = cv2.getRotationMatrix2D((roiw/2, roih/2), angle, 1)\n",
    "    roi = cv2.warpAffine(img, matrix, (roiw, roih))\n",
    "    # ------------------- 기울기 조정 fin -------------------\n",
    "\n",
    "    gray_2 = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "    gray_2 = cv2.resize(gray_2, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur_2 = cv2.GaussianBlur(gray_2, (5,5), 0)\n",
    "\n",
    "    ## 이미지 흑백 대조하기, 최적 임계값을 자동으로 추출하는 Otsus 사용\n",
    "    ret, thresh = cv2.threshold(blur_2, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    ## 확장을 위한 커널 생성\n",
    "    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    ## 글씨 이미지 크기 확장\n",
    "    dilation = cv2.dilate(thresh, rect_kern, iterations = 1)\n",
    "\n",
    "    blur_3 = cv2.GaussianBlur(dilation, (5,5), 0)\n",
    "    \n",
    "    plate_num = \"\"\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(blur_3, config='-c tessedit_char_whitelist=0123456789 --psm 7 --oem 1')\n",
    "        plate_num = re.sub('[\\W_]+', '', text)            \n",
    "    except:\n",
    "        text = None\n",
    "    \n",
    "    plate_num = re.sub('[\\W_]+', '', text)   \n",
    "    return plate_num[-4:]\n",
    "            \n",
    "        \n",
    "# ------------------------- OCR_v4 -------------------------\n",
    "def OCR_bn(img):\n",
    "    img = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    \n",
    "    ## 이미지 흑백 대조하기, 최적 임계값을 자동으로 추출하는 Otsus 사용\n",
    "    ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    ## 확장을 위한 커널 생성\n",
    "    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    ## 글씨 이미지 크기 확장\n",
    "    dilation = cv2.dilate(thresh, rect_kern, iterations = 1)\n",
    "    blur_2 = cv2.GaussianBlur(dilation, (5,5), 0)\n",
    "    \n",
    "    plate_num = \"\"\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(blur_2, config='-c tessedit_char_whitelist=0123456789 --psm 7 --oem 1')            \n",
    "    except:\n",
    "        text = None\n",
    "        \n",
    "    plate_num = re.sub('[\\W_]+', '', text)   \n",
    "    return plate_num[-4:]\n",
    "\n",
    "# ------------------------- OCR_v5 -------------------------\n",
    "def OCR_easy(img):\n",
    "    img = cv2.imread(img)\n",
    "    blurred = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    \n",
    "    plate_num = \"\"\n",
    "    try:\n",
    "        text = result = reader.readtext(blurred)[0][-2]\n",
    "    except:\n",
    "        text = None\n",
    "        \n",
    "    plate_num = re.findall('\\d+', result) \n",
    "    return plate_num[-4:]\n",
    "\n",
    "'''\n",
    "# ------------------------- 목표 버스 일치 여부 확인 함수 -------------------------\n",
    "def tfBusNum(store_img, busNum, busLicenseNum):\n",
    "    for img in store_img:\n",
    "        try:\n",
    "            preBusNum = OCR_bn(img) # OCR_v1 output\n",
    "            preBusNum2 = OCR_pn(img) # OCR_v1 output\n",
    "            preBusNum3 = OCR_pn2(img) # OCR_v1 output\n",
    "            preBusNum4 = OCR_pn3(img) # OCR_v1 output\n",
    "            print(f'busNum: {busNum}') # 목표 버스 번호 \n",
    "            print(f'busLicenseNum: {busLicenseNum}') # 목표 버스 차량번호\n",
    "            print('---------------예측-------------------')\n",
    "            print(f'prediction busNum: {preBusNum}')\n",
    "            print(f'prediction busNum2: {preBusNum2}')\n",
    "            print(f'prediction busNum3: {preBusNum3}')\n",
    "            print(f'prediction busNum4: {preBusNum4}')\n",
    "\n",
    "            # 목표 버스 번호와 일치 여부 확인\n",
    "            if preBusNum == busNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "            if preBusNum2 == busNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "            if preBusNum3 == busNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "            if preBusNum4 == busNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "\n",
    "            # 목표 버스 차량번호와 일치 여부 확인\n",
    "            if preBusNum == busLicenseNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "            if preBusNum2 == busLicenseNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "            if preBusNum3 == busLicenseNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "            if preBusNum4 == busLicenseNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "        except:\n",
    "            continue\n",
    "'''\n",
    "    \n",
    "# ------------------------- 목표 버스 일치 여부 확인 함수 -------------------------\n",
    "def tfBusNum(store_img, busNum, busLicenseNum):\n",
    "    for img in store_img:\n",
    "        try:\n",
    "            preBusNum = OCR_easy(img) # OCR_v1 output\n",
    "            print(f'busNum: {busNum}') # 목표 버스 번호 \n",
    "            print(f'busLicenseNum: {busLicenseNum}') # 목표 버스 차량번호\n",
    "            print('---------------예측-------------------')\n",
    "            print(f'prediction busNum: {preBusNum}')\n",
    "\n",
    "            \n",
    "            # 목표 버스 번호와 일치 여부 확인\n",
    "            if preBusNum == busNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "\n",
    "            # 목표 버스 차량번호와 일치 여부 확인\n",
    "            if preBusNum == busLicenseNum:\n",
    "                print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "                print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "                return True\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "# ------------------------- 버스 문 인식 함수 -------------------------\n",
    "def door(img):\n",
    "    # 현재 이미지 불러오기\n",
    "    results_img = model2(img)\n",
    "    results_img_xy_df = results_img.pandas().xyxy[0]\n",
    "\n",
    "    if len(results_img_xy_df[results_img_xy_df['name']=='door_open']) != 0:\n",
    "        print('***************if-1-door**************')\n",
    "        x_center = (results_img_xy_df[results_img_xy_df['name']=='door_open'].iloc[:,2] + results_img_xy_df[results_img_xy_df['name']=='door_open'].iloc[:,0])/2\n",
    "\n",
    "    if len(results_img_xy_df[results_img_xy_df['name']=='door']) != 0:\n",
    "        print('***************if-2-door**************')\n",
    "        x_center = (results_img_xy_df[results_img_xy_df['name']=='door'].iloc[:,2] + results_img_xy_df[results_img_xy_df['name']=='door'].iloc[:,0])/2\n",
    "        \n",
    "    else:\n",
    "        print('***************else-door**************')\n",
    "        # 인식 안됨\n",
    "        return 'X'\n",
    "\n",
    "    # 카메라 중점\n",
    "    print(x_center)\n",
    "    cam_view_center = 360\n",
    "    if cam_view_center*0.6 < float(x_center) < cam_view_center*1.4:\n",
    "        return 'C'\n",
    "        \n",
    "    elif cam_view_center < float(x_center):\n",
    "        return 'R'\n",
    "        \n",
    "    elif cam_view_center > float(x_center):\n",
    "        return 'L'\n",
    "    \n",
    "\n",
    "#연결 확인\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"connect..\" + str(rc))\n",
    "    if rc == 0:\n",
    "        client.subscribe(\"eyeson/#\")\n",
    "        print(1)\n",
    "    else:\n",
    "        print(\"연결실패\")\n",
    "\n",
    "\n",
    "def ai(uuid,img_pink,img_bus,store_img, busNum, busLicenseNum):\n",
    "    print('333')\n",
    "    \n",
    "    \n",
    "    # ------------------------- 표지판 인식 while문(Center가 30번 나올때까지 반복) -------------------------\n",
    "    pre = None # 직전 표지판 방향\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            direction = notice(img_pink) # 현재 표지판 방향\n",
    "        except:\n",
    "            direction = None\n",
    "            \n",
    "        # R: 오른쪽에 표지판이 있습니다\n",
    "        # L: 왼쪽에 표지판이 있습니다\n",
    "        # C: 정면에 표지판이 있습니다\n",
    "        if direction == 'R':\n",
    "            cnt += 1\n",
    "            if pre != direction or cnt >= 30: # 직전 표지판 방향과 현재 표지판 방향이 다르거나 cnt가 30 이상이면 퍼블리싱\n",
    "                publish.single(\"eyeson/\" + uuid,'ai/noticeInfo/R', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            pre = direction\n",
    "            continue\n",
    "        if direction == 'L':\n",
    "            cnt += 1\n",
    "            if pre != direction or cnt >= 30:\n",
    "                publish.single(\"eyeson/\" + uuid,'ai/noticeInfo/L', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            pre = direction\n",
    "            continue\n",
    "        if direction == 'C':\n",
    "            cnt += 1\n",
    "            print(f'<<<<<정면입니다>>>>> cnt: {cnt}')\n",
    "            if pre != direction:\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/noticeInfo/C', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            if cnt >= 30:\n",
    "                # center가 30번 누적으로 나오면 알림 주고 break\n",
    "                # correctC: 정면에 표지판이 있습니다. 이 방향으로 다가가주세요\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/noticeInfo/correctC', hostname=\"15.164.46.54\")\n",
    "                break\n",
    "            pre = direction\n",
    "            continue\n",
    "        if direction == 'X':\n",
    "            cnt += 1\n",
    "            if pre != direction or cnt >= 30:\n",
    "                # X: 표지판이 인식되지 않았습니다. 차도 주위를 둘러봐주세요\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/noticeInfo/X', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            pre = direction\n",
    "            continue\n",
    "        else:\n",
    "            cnt = 0\n",
    "            continue\n",
    "\n",
    "\n",
    "    # ------------------------- 버스 번호 인식 함수(표지판 인식이 끝난 후 실행) -------------------------\n",
    "    while True:\n",
    "        try:\n",
    "            objectDetection(img_bus) # yolov5s 모델로 input image 디텍팅 후 크롭된 이미지 저장\n",
    "        except:\n",
    "            pass\n",
    "        # 버스 번호 crop 이미지 저장\n",
    "\n",
    "        # OCR 통해 버스 번호 일치 여부 확인, True 나오면 break\n",
    "        if tfBusNum(store_img, busNum, busLicenseNum):\n",
    "            print(uuid + \"타겟버스\")\n",
    "            publish.single(\"eyeson/\" + uuid,\"ai/targetBus\", hostname=\"15.164.46.54\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # ------------------------- 문 방향 인식 함수(목표 버스가 일치함을 확인 후 실행) -------------------------            \n",
    "    pre = None\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            direction = door(img_bus)\n",
    "        except:\n",
    "            direction = None\n",
    "\n",
    "        # R: 오른쪽에 문이 있습니다\n",
    "        # L: 왼쪽에 문이 있습니다\n",
    "        # C: 정면에 문이 있습니다\n",
    "        if direction == 'R':\n",
    "            cnt += 1\n",
    "            if pre != direction or cnt >= 30:\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/doorInfo/R', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            pre = direction\n",
    "            continue\n",
    "        if direction == 'L':\n",
    "            cnt += 1\n",
    "            if pre != direction or cnt >= 30:\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/doorInfo/L', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            pre = direction\n",
    "            continue\n",
    "        if direction == 'C':\n",
    "            cnt += 1\n",
    "            if pre != direction:\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/doorInfo/C', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            if cnt >= 30:\n",
    "                # center가 30번 누적으로 나오면 알림 주고 break\n",
    "                # correctC: 정면에 문이 있습니다. 이 방향으로 다가가주세요\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/doorInfo/correctC', hostname=\"15.164.46.54\")\n",
    "                break\n",
    "            pre = direction\n",
    "            continue\n",
    "        if direction == 'X':\n",
    "            cnt += 1\n",
    "            if pre != direction or cnt >= 30:\n",
    "                # X: 문이 인식되지 않았습니다. 차도 주위를 둘러봐주세요\n",
    "                publish.single(\"eyeson/\" + uuid, 'ai/doorInfo/X', hostname=\"15.164.46.54\")\n",
    "                cnt = 0\n",
    "            pre = direction\n",
    "            continue\n",
    "        else:\n",
    "            cnt = 0\n",
    "            continue\n",
    "    \n",
    "\n",
    "# 메시지가 도착됐을때 처리할 일들 - 여러가지 장비 제어하기, Mongodb에 저장\n",
    "def on_message(client, userdata, msg): # 최초 1번\n",
    "    try:\n",
    "        #global img_bus, busNum, busLicenseNum, base, store_img, uuid, img_pink\n",
    "        myval = msg.payload.decode(\"utf-8\")\n",
    "        myval = myval.replace(\" \", \"\")\n",
    "        myval = myval.split(\"/\")\n",
    "        mytopic = msg.topic.split(\"/\")\n",
    "        uuid = mytopic[1]\n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>\" + uuid + \"uuid 확인\")\n",
    "        print(myval)\n",
    "        base = '/home/lab08/yolov5/runs/hub/exp/crops/'\n",
    "#         img_pink = '/home/lab19/ai_env_mino/yolov5/' + uuid + '.jpg'\n",
    "        img_pink = '/home/lab08/yolov5/'+uuid+'.jpg'\n",
    "#         img_pink = '/home/lab08/yolov5/test_pink.jpg'\n",
    "\n",
    "#         img_bus = './test_bus.jpg'\n",
    "        img_bus = '/home/lab08/yolov5/'+uuid+'.jpg'\n",
    "#         img_bus = './'+uuid+'.jpg'\n",
    "        store_img = [base+'bus_num_fr/'+uuid+'.jpg', base+'bus_num_side/'+uuid+'.jpg', base+'license_plate/'+uuid+'.jpg']\n",
    "\n",
    "         \n",
    "        if myval[0] == \"android\":\n",
    "            if myval[1] == \"ai\":\n",
    "                busNum = myval[2]\n",
    "                print(busNum)\n",
    "                busLicenseNum = myval[3]\n",
    "                print(busLicenseNum)\n",
    "            #     uuid = '12345'\n",
    "#                 busNum = '5714'\n",
    "#                 busLicenseNum = '2914'\n",
    "                print(\"bigData last 확인\")\n",
    "\n",
    "\n",
    "                # 표지판 인식 센터 잡기 -> 목표 버스 확인 -> 도어 인식 센터 잡기\n",
    "                # subCamera.py 에선 실시간으로 바이트로 넘어오는 파일을 이미지로 저장(특정 폴더에)\n",
    "                # subBusTarget.py 는 최초 1번 정보를 받고 while문으로 갱신되는 이미지를 예측\n",
    "                \n",
    "                # 쓰레드 설정 \n",
    "                print('111')\n",
    "                thread = threading.Thread(target=ai, args=(uuid,img_pink,img_bus,store_img,busNum,busLicenseNum,))\n",
    "                # \n",
    "                print('222')\n",
    "                # 쓰레드 시작\n",
    "                thread.start()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "mqttClient = mqtt.Client()  # 클라이언트 객체 생성\n",
    "# 브로커에 연결이되면 내가 정의해놓은 on_connect함수가 실행되도록 등록\n",
    "mqttClient.on_connect = on_connect\n",
    "\n",
    "# 브로커에서 메시지가 전달되면 내가 등록해 놓은 on_message함수가 실행\n",
    "mqttClient.on_message = on_message\n",
    "\n",
    "# 브로커에 연결하기\n",
    "mqttClient.connect(\"15.164.46.54\", 1883, 60)\n",
    "\n",
    "# 토픽이 전달될때까지 수신대기\n",
    "mqttClient.loop_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt] *",
   "language": "python",
   "name": "conda-env-pt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
